{
  "best_global_step": 200,
  "best_metric": 0.7705944180488586,
  "best_model_checkpoint": "/content/drive/MyDrive/ML-Techniques-Fine-tuning/healthbot_tinyllama_lora/checkpoint-200",
  "epoch": 2.6666666666666665,
  "eval_steps": 100,
  "global_step": 200,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "entropy": 1.25033203125,
      "epoch": 0.3333333333333333,
      "grad_norm": 0.49609375,
      "learning_rate": 0.00019843779142227256,
      "loss": 1.3204144287109374,
      "mean_token_accuracy": 0.7137354229390621,
      "num_tokens": 116576.0,
      "step": 25
    },
    {
      "entropy": 0.85757080078125,
      "epoch": 0.6666666666666666,
      "grad_norm": 0.3359375,
      "learning_rate": 0.00018547524236003674,
      "loss": 0.8735003662109375,
      "mean_token_accuracy": 0.8023420186340808,
      "num_tokens": 236488.0,
      "step": 50
    },
    {
      "entropy": 0.8322412109375,
      "epoch": 1.0,
      "grad_norm": 0.322265625,
      "learning_rate": 0.00016102230655313076,
      "loss": 0.8578530120849609,
      "mean_token_accuracy": 0.8064479905366898,
      "num_tokens": 352982.0,
      "step": 75
    },
    {
      "entropy": 0.7919287109375,
      "epoch": 1.3333333333333333,
      "grad_norm": 0.380859375,
      "learning_rate": 0.0001283661778334297,
      "loss": 0.7828834533691407,
      "mean_token_accuracy": 0.8193605162203312,
      "num_tokens": 469648.0,
      "step": 100
    },
    {
      "epoch": 1.3333333333333333,
      "eval_entropy": 0.7761360677083333,
      "eval_loss": 0.7771770358085632,
      "eval_mean_token_accuracy": 0.8146159772078196,
      "eval_num_tokens": 469648.0,
      "eval_runtime": 30.148,
      "eval_samples_per_second": 4.975,
      "eval_steps_per_second": 4.975,
      "step": 100
    },
    {
      "entropy": 0.733775634765625,
      "epoch": 1.6666666666666665,
      "grad_norm": 0.3828125,
      "learning_rate": 9.1896800449264e-05,
      "loss": 0.741122817993164,
      "mean_token_accuracy": 0.828832739442587,
      "num_tokens": 587501.0,
      "step": 125
    },
    {
      "entropy": 0.761754150390625,
      "epoch": 2.0,
      "grad_norm": 0.36328125,
      "learning_rate": 5.651673143248508e-05,
      "loss": 0.7618531799316406,
      "mean_token_accuracy": 0.8250824370980263,
      "num_tokens": 705964.0,
      "step": 150
    },
    {
      "entropy": 0.747293701171875,
      "epoch": 2.3333333333333335,
      "grad_norm": 0.404296875,
      "learning_rate": 2.6982092729416587e-05,
      "loss": 0.73371826171875,
      "mean_token_accuracy": 0.8295689903199672,
      "num_tokens": 824280.0,
      "step": 175
    },
    {
      "entropy": 0.682696533203125,
      "epoch": 2.6666666666666665,
      "grad_norm": 0.380859375,
      "learning_rate": 7.263208514547548e-06,
      "loss": 0.6636478424072265,
      "mean_token_accuracy": 0.8457304205000401,
      "num_tokens": 940709.0,
      "step": 200
    },
    {
      "epoch": 2.6666666666666665,
      "eval_entropy": 0.7221940104166666,
      "eval_loss": 0.7705944180488586,
      "eval_mean_token_accuracy": 0.8180344935258229,
      "eval_num_tokens": 940709.0,
      "eval_runtime": 29.9851,
      "eval_samples_per_second": 5.002,
      "eval_steps_per_second": 5.002,
      "step": 200
    }
  ],
  "logging_steps": 25,
  "max_steps": 225,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 200,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 5910256763744256.0,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
